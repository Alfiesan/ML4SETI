{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETI Test Set Classification Accuracy\n",
    "\n",
    "This notebook provides the code needed to calculate the performance of your signal classification models using the PREVIEW test set (see [Step 1. Get Data notebook](https://github.com/setiQuest/ML4SETI/blob/master/tutorials/Step_1_Get_Data.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import csv\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_list = ['brightpixel', 'narrowband', 'narrowbanddrd', 'noise', 'squarepulsednarrowband', 'squiggle', 'squigglesquarepulsednarrowband']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fieldnames = ['uuid'] + class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Helper functions for parsing the data and using sklearn to print scoring metrics\n",
    "\n",
    "def classChooser(listOfDictionaryScores):\n",
    "    results = []\n",
    "    for row in listOfDictionaryScores:\n",
    "        rowscores = dict((k, float(row[k])) for k in class_list)\n",
    "        maxclass = max(rowscores.iteritems(), key=operator.itemgetter(1))[0]\n",
    "        results.append({'UUID':row['uuid'], 'SIGNAL_CLASSIFICATION':maxclass})\n",
    "        \n",
    "    return results\n",
    "\n",
    "def printsklearnScores(y_true, y_pred, y_prob):\n",
    "    \n",
    "    print sklearn.metrics.classification_report(y_true,y_pred, digits=5)\n",
    "    print sklearn.metrics.confusion_matrix(y_true,y_pred)\n",
    "    print(\"Classification accuracy: %0.6f\" % sklearn.metrics.accuracy_score(y_true,y_pred) )\n",
    "    print(\"Log Loss: %0.6f\" % sklearn.metrics.log_loss(y_true,y_prob) )\n",
    "    \n",
    "def score(resultsFile):\n",
    "\n",
    "    testSetFile = 'private_list_primary_v3_testset_preview_uuid_class_29june_2017.csv'\n",
    "    \n",
    "    actual_uuid = csv.DictReader(open(testSetFile))\n",
    "    actual_uuid_list = [x for x in actual_uuid]\n",
    "    actual_uuid_list_sorted = sorted(actual_uuid_list, key=lambda k: k['UUID']) \n",
    "\n",
    "    classifier_results = csv.DictReader(open(resultsFile), fieldnames=fieldnames)\n",
    "    classifier_results_list = [x for x in classifier_results]\n",
    "    classifier_results_list_sorted = sorted(classifier_results_list, key=lambda k: k['uuid']) \n",
    "\n",
    "    #yc = classChooser(classifier_results_list_sorted)\n",
    "    #print yc[:5]\n",
    "    \n",
    "    y_true = [x['SIGNAL_CLASSIFICATION'] for x in actual_uuid_list_sorted]\n",
    "    y_pred = [x['SIGNAL_CLASSIFICATION'] for x in classChooser(classifier_results_list_sorted)]\n",
    "    y_prob = [[float(row[cl]) for cl in class_list] for row in classifier_results_list_sorted] \n",
    "    \n",
    "    printsklearnScores(y_true, y_pred, y_prob)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring a Scorecard\n",
    "\n",
    "The Preview test data set can be obtained in the [Step 1. Get Data notebook](https://github.com/setiQuest/ML4SETI/blob/master/tutorials/Step_1_Get_Data.ipynb).  Using your model, you can generate a scorecard for this preview test data set. Your scorecard must be a CSV file with 8 columns. The first column value will contain the UUID and the next 7 will contain the probability estimates for each of the classes that were produced by your model. See the [Judging Information notebook for more information](https://github.com/setiQuest/ML4SETI/blob/master/Judging_Criteria.ipynb).\n",
    "\n",
    "Now you can score the scorecard you just created using this code. [We now are providing the Preview test data set key! This will give you the exact answers, so don't cheat.]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "### Using the Example Scorecard.\n",
    "\n",
    "On the [Judging Information notebook](https://github.com/setiQuest/ML4SETI/blob/master/Judging_Criteria.ipynb) there is a link to download an example scorecard. Your scorecard should be similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                precision    recall  f1-score   support\n",
      "\n",
      "                   brightpixel    0.12349   0.12812   0.12577       320\n",
      "                    narrowband    0.16467   0.14474   0.15406       380\n",
      "                 narrowbanddrd    0.19274   0.19885   0.19574       347\n",
      "                         noise    0.12392   0.12798   0.12592       336\n",
      "        squarepulsednarrowband    0.16298   0.17302   0.16785       341\n",
      "                      squiggle    0.18106   0.17711   0.17906       367\n",
      "squigglesquarepulsednarrowband    0.13043   0.13003   0.13023       323\n",
      "\n",
      "                   avg / total    0.15525   0.15493   0.15495      2414\n",
      "\n",
      "[[41 51 50 38 35 60 45]\n",
      " [47 55 61 65 48 56 48]\n",
      " [42 46 69 52 44 42 52]\n",
      " [47 47 56 43 53 41 49]\n",
      " [42 42 43 47 59 56 52]\n",
      " [60 42 45 64 57 65 34]\n",
      " [53 51 34 38 66 39 42]]\n",
      "Classification accuracy: 0.154930\n",
      "Log Loss: 2.230604\n"
     ]
    }
   ],
   "source": [
    "score('example_scorecard_codechallenge_v3_testset_preview.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "### Using the Preview Test Set Key.\n",
    "\n",
    "If I use the preview test set key, then I will get a perfect score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                precision    recall  f1-score   support\n",
      "\n",
      "                   brightpixel    1.00000   1.00000   1.00000       320\n",
      "                    narrowband    1.00000   1.00000   1.00000       380\n",
      "                 narrowbanddrd    1.00000   1.00000   1.00000       347\n",
      "                         noise    1.00000   1.00000   1.00000       336\n",
      "        squarepulsednarrowband    1.00000   1.00000   1.00000       341\n",
      "                      squiggle    1.00000   1.00000   1.00000       367\n",
      "squigglesquarepulsednarrowband    1.00000   1.00000   1.00000       323\n",
      "\n",
      "                   avg / total    1.00000   1.00000   1.00000      2414\n",
      "\n",
      "[[320   0   0   0   0   0   0]\n",
      " [  0 380   0   0   0   0   0]\n",
      " [  0   0 347   0   0   0   0]\n",
      " [  0   0   0 336   0   0   0]\n",
      " [  0   0   0   0 341   0   0]\n",
      " [  0   0   0   0   0 367   0]\n",
      " [  0   0   0   0   0   0 323]]\n",
      "Classification accuracy: 1.000000\n",
      "Log Loss: 0.000000\n"
     ]
    }
   ],
   "source": [
    "#Test with the scoreboard key. This should get 100% accuracy\n",
    "score('private_list_primary_v3_testset_preview_scoreboard_key_29june_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                precision    recall  f1-score   support\n",
      "\n",
      "                   brightpixel    0.98148   0.82812   0.89831       320\n",
      "                    narrowband    0.98870   0.92105   0.95368       380\n",
      "                 narrowbanddrd    0.97101   0.96542   0.96821       347\n",
      "                         noise    0.77622   0.99107   0.87059       336\n",
      "        squarepulsednarrowband    0.93175   0.92082   0.92625       341\n",
      "                      squiggle    0.99169   0.97548   0.98352       367\n",
      "squigglesquarepulsednarrowband    0.97170   0.95666   0.96412       323\n",
      "\n",
      "                   avg / total    0.94576   0.93786   0.93892      2414\n",
      "\n",
      "[[265   0   0  53   1   0   1]\n",
      " [  1 350   8  10  10   0   1]\n",
      " [  0   1 335   7   4   0   0]\n",
      " [  1   0   0 333   2   0   0]\n",
      " [  1   3   1  22 314   0   0]\n",
      " [  0   0   1   1   0 358   7]\n",
      " [  2   0   0   3   6   3 309]]\n",
      "Classification accuracy: 0.937862\n",
      "Log Loss: 0.220428\n"
     ]
    }
   ],
   "source": [
    "score(\"results_EffSubZee_21july.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of how to score a CV set\n",
    "\n",
    "You can use the score functions above with a cross-validation data set from the training data set to measure your model performance.  Then you won't have to always use the preview test set. \n",
    "\n",
    "The following code will show you how to split up your training data into a training set and CV set. Then we'll use some fake models to create some predicted values for our cross-validation set. Using those predicted values, we'll use the `printsklearnScores` function above.\n",
    "\n",
    "<br>\n",
    "\n",
    "### 1.\n",
    "First, let's split our data up into a training data set and a cross-validation set. We start with the primay small \n",
    "index file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexfile = 'public_list_primary_v3_small_21june_2017.csv'\n",
    "indexfile_uuid = csv.DictReader(open(indexfile))\n",
    "indexfile_uuid_list = [x for x in indexfile_uuid]\n",
    "indexfile_uuid_list = sorted(indexfile_uuid_list, key=lambda k: k['UUID'])\n",
    "\n",
    "X = [x['UUID'] for x in indexfile_uuid_list]\n",
    "y = [class_list.index(x['SIGNAL_CLASSIFICATION']) for x in indexfile_uuid_list] #also convert from class name to a number\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## 2.\n",
    "In normal operation, you'd then use the `X_train` set of UUIDs to grab the `<UUID>.dat`  data files and produce spectrograms and features. You'd then pass your features, along with `y_train`, which contains\n",
    "your labels, to your model for training. \n",
    "\n",
    "<br>\n",
    "## 3. \n",
    "Next, you'd take the `X_cv` set of UUIDs, extract the necessary spectrogram and features and pass that to your model\n",
    "in order to predict their class. In the code below, there are two fake models: `perfectModel` and `randomModel`. Each of them return a 2d array, M x K, where M is the number of samples and K is the number of classes. The values for each row are the class probability predictions. The `randomModel` produces random probabilities. The `perfectModel` actually uses the known values in the y_cv -- so it will produce a perfect score. Obviously, your model should produce scores that result in a \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomModel(X_cv):\n",
    "    y_prob = np.random.rand(len(X_cv), len(class_list))\n",
    "    return (y_prob.T / y_prob.sum(axis=1)).T\n",
    "\n",
    "def perfectModel(X_cv):\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    ycv = np.array(y_cv).reshape(1,-1)\n",
    "    ycv_onehot = encoder.fit_transform(ycv.T)\n",
    "    return ycv_onehot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The randomModel class produces random probability estimates\n",
      "[[ 0.21622444  0.19336502  0.09548523  0.20304027  0.0748022   0.02166179\n",
      "   0.19542104]\n",
      " [ 0.13087778  0.20344906  0.06237559  0.04153681  0.284838    0.19789609\n",
      "   0.07902665]\n",
      " [ 0.12452463  0.09598028  0.14679418  0.2344678   0.20976057  0.083537\n",
      "   0.10493554]\n",
      " [ 0.18092884  0.22081595  0.1201021   0.17731216  0.1036566   0.11998787\n",
      "   0.07719647]\n",
      " [ 0.14025169  0.02794412  0.30522047  0.27883455  0.09998314  0.10675682\n",
      "   0.04100922]]\n",
      "\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "                   brightpixel    0.09184   0.08738   0.08955       103\n",
      "                    narrowband    0.14151   0.15000   0.14563       100\n",
      "                 narrowbanddrd    0.14286   0.11765   0.12903       102\n",
      "                         noise    0.14000   0.16092   0.14973        87\n",
      "        squarepulsednarrowband    0.16514   0.17822   0.17143       101\n",
      "                      squiggle    0.19811   0.20588   0.20192       102\n",
      "squigglesquarepulsednarrowband    0.10309   0.09524   0.09901       105\n",
      "\n",
      "                   avg / total    0.14010   0.14143   0.14040       700\n",
      "\n",
      "[[ 9 19 15 12 15 17 16]\n",
      " [14 15  9 22 14 16 10]\n",
      " [24 14 12 13 10 11 18]\n",
      " [ 4 22 11 14 17 10  9]\n",
      " [12 14 12 13 18 14 18]\n",
      " [14 12 12 14 13 21 16]\n",
      " [21 10 13 12 22 17 10]]\n",
      "Classification accuracy: 0.141429\n",
      "Log Loss: 2.323974\n"
     ]
    }
   ],
   "source": [
    "y_prob = randomModel(X_cv)\n",
    "y_true = [class_list[i] for i in y_cv]\n",
    "y_pred = [class_list[probarray.argmax()] for probarray in y_prob]\n",
    "\n",
    "print 'The randomModel class produces random probability estimates'\n",
    "print y_prob[:5]\n",
    "print ''\n",
    "\n",
    "printsklearnScores(y_true, y_pred, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]]\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "                   brightpixel    1.00000   1.00000   1.00000       103\n",
      "                    narrowband    1.00000   1.00000   1.00000       100\n",
      "                 narrowbanddrd    1.00000   1.00000   1.00000       102\n",
      "                         noise    1.00000   1.00000   1.00000        87\n",
      "        squarepulsednarrowband    1.00000   1.00000   1.00000       101\n",
      "                      squiggle    1.00000   1.00000   1.00000       102\n",
      "squigglesquarepulsednarrowband    1.00000   1.00000   1.00000       105\n",
      "\n",
      "                   avg / total    1.00000   1.00000   1.00000       700\n",
      "\n",
      "[[103   0   0   0   0   0   0]\n",
      " [  0 100   0   0   0   0   0]\n",
      " [  0   0 102   0   0   0   0]\n",
      " [  0   0   0  87   0   0   0]\n",
      " [  0   0   0   0 101   0   0]\n",
      " [  0   0   0   0   0 102   0]\n",
      " [  0   0   0   0   0   0 105]]\n",
      "Classification accuracy: 1.000000\n",
      "Log Loss: 0.000000\n"
     ]
    }
   ],
   "source": [
    "y_prob = perfectModel(X_cv)\n",
    "y_true = [class_list[i] for i in y_cv]\n",
    "y_pred = [class_list[probarray.argmax()] for probarray in y_prob]\n",
    "\n",
    "print y_prob[:5]\n",
    "\n",
    "printsklearnScores(y_true, y_pred, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
