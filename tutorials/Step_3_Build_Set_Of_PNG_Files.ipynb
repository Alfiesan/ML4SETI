{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Build PNG Files\n",
    "\n",
    "In this notebook, we'll take the `basic` data set, use `ibmseti` Python package to convert each data file into a spectrogram, then save as `.png` files.\n",
    "\n",
    "\n",
    "Also, we'll split the data set into a training set and a test set and create a handful of zip files for each class. This will dovetail into the next tutorial where we will train a custom Watson Visual Recognition classifier (we will use the zip files of pngs) and measure it's performance with the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import cStringIO\n",
    "import glob\n",
    "import json\n",
    "import requests\n",
    "import ibmseti\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Making a local folder to put my data.\n",
    "\n",
    "#NOTE: YOU MUST do something like this on a Spark Enterprise cluster at the hackathon so that\n",
    "#you can put your data into a separate local file space. Otherwise, you'll likely collide with \n",
    "#your fellow participants. \n",
    "\n",
    "mydatafolder = 'my_team_name_data_folder/basic4'\n",
    "if os.path.exists(mydatafolder) is False:\n",
    "    os.makedirs(mydatafolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "basic4zip = 'https://dal.objectstorage.open.softlayer.com/v1/AUTH_cdbef52bdf7a449c96936e1071f0a46b/simsignals_basic_v2/basic4.zip'\n",
    "os.system('curl {} > {}/{}'.format(basic4zip, mydatafolder, 'basic4.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic4.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls adam_data_folder/basic4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "outputpng_folder = 'adam_data_folder/png'\n",
    "if os.path.exists(outputpng_folder) is False:\n",
    "    os.makedirs(outputpng_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "zz = zipfile.ZipFile(mydatafolder + '/' + 'basic4.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Use `ibmseti`, or other methods, to draw the spectrograms\n",
    "\n",
    "def draw_spectrogram(data):\n",
    "    \n",
    "    aca = ibmseti.compamp.SimCompamp(data)\n",
    "    spec = aca.get_spectrogram()\n",
    "\n",
    "    # Instead of using SimCompAmp.get_spectrogram method\n",
    "    # perform your own signal processing here before you create the spectrogram\n",
    "    #\n",
    "    # SimCompAmp.get_spectrogram is relatively simple. Here's the code to reproduce it:\n",
    "    #\n",
    "    # header, raw_data = r.content.split('\\n',1)\n",
    "    # complex_data = np.frombuffer(raw_data, dtype='i1').astype(np.float32).view(np.complex64)\n",
    "    # shape = (32, 6144)\n",
    "    # spec = np.abs( np.fft.fftshift( np.fft.fft( complex_data.reshape(*shape) ), 1) )**2\n",
    "    # \n",
    "    # But instead of the line above, can you maniputlate `complex_data` with signal processing\n",
    "    # techniques in the time-domain (windowing?, de-chirp?), or manipulate the output of the \n",
    "    # np.fft.fft process in a way to improve the signal to noise (Welch periodogram, subtract noise model)? \n",
    "    # \n",
    "    # example: Apply Hanning Window\n",
    "    # complex_data = complex_data.reshape(*shape)\n",
    "    # complex_data = complex_data * np.hanning(complex_data.shape[1])\n",
    "    # spec = np.abs( np.fft.fftshift( np.fft.fft( complex_data ), 1) )**2\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))   \n",
    "\n",
    "    # do different color mappings affect Watson's classification accuracy?\n",
    "    # ax.imshow(np.log(spec), aspect = 0.5*float(spec.shape[1]) / spec.shape[0], cmap='hot')\n",
    "    # ax.imshow(np.log(spec), aspect = 0.5*float(spec.shape[1]) / spec.shape[0], cmap='gray')\n",
    "    # ax.imshow(np.log(spec), aspect = 0.5*float(spec.shape[1]) / spec.shape[0], cmap='Greys')\n",
    "    \n",
    "    ax.imshow(np.log(spec), aspect = 0.5*float(spec.shape[1]) / spec.shape[0], cmap='gray')\n",
    "    \n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "total = len(zz.namelist())\n",
    "for fn in zz.namelist():\n",
    "    data = zz.open(fn).read()\n",
    "    fig = draw_spectrogram(data)\n",
    "    png_file = fn + '.png'\n",
    "    if count % 200 == 0:\n",
    "        print 'completed', count, 'out of', total\n",
    "        \n",
    "    fig.savefig(outputpng_folder + '/' + png_file)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Create Training / Test sets\n",
    "\n",
    "Using the `basic` list, we'll create training and test sets for each signal class. Then we'll archive the `.png` files into a handful of `.zip` files (We need the .zip files to be smaller than 100 MB because there is a limitation with the size of batches of data that are uploaded to Watson Visual Recognition when training a classifier.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 4000 files\n"
     ]
    }
   ],
   "source": [
    "# Grab the Basic file list in order to \n",
    "# Organize the Data into classes\n",
    "\n",
    "r = requests.get('https://dal.objectstorage.open.softlayer.com/v1/AUTH_cdbef52bdf7a449c96936e1071f0a46b/simsignals_files/public_list_basic_v2_26may_2017.csv', timeout=(9.0, 21.0))\n",
    "\n",
    "uuids_classes_as_list = r.text.split('\\n')[1:-1]  #slice off the first line (header) and last line (empty)\n",
    "\n",
    "def row_to_json(row):\n",
    "    uuid,sigclass = row.split(',')\n",
    "    return {'uuid':uuid, 'signal_classification':sigclass}\n",
    "\n",
    "uuids_classes_as_list = map(lambda row: row_to_json(row), uuids_classes_as_list)\n",
    "print \"found {} files\".format(len(uuids_classes_as_list))\n",
    "\n",
    "uuids_group_by_class = {}\n",
    "for item in uuids_classes_as_list:\n",
    "    uuids_group_by_class.setdefault(item['signal_classification'], []).append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squiggle: training set size: 700\n",
      "squiggle: test set size: 300\n",
      "narrowband: training set size: 700\n",
      "narrowband: test set size: 300\n",
      "noise: training set size: 700\n",
      "noise: test set size: 300\n",
      "narrowbanddrd: training set size: 700\n",
      "narrowbanddrd: test set size: 300\n"
     ]
    }
   ],
   "source": [
    "training_percentage = 0.70\n",
    "\n",
    "training_set_group_by_class = {}\n",
    "test_set_group_by_class = {}\n",
    "for k, v in uuids_group_by_class.iteritems():\n",
    "    \n",
    "    total = len(v)\n",
    "    training_size = int(total * training_percentage)\n",
    "\n",
    "    training_set = v[0:training_size]\n",
    "    test_set = v[training_size:total]\n",
    "    \n",
    "    training_set_group_by_class[k] = training_set\n",
    "    test_set_group_by_class[k] = test_set\n",
    "    \n",
    "    print '{}: training set size: {}'.format(k, len(training_set))\n",
    "    print '{}: test set size: {}'.format(k, len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'signal_classification': u'noise',\n",
       " 'uuid': u'498becc2-3693-45b3-8533-50e93532706a'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_group_by_class['noise'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fnames = [outputpng_folder + '/' + vv['uuid'] + '.dat.png' for vv in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "zipfilefolder = 'my_team_name_data_folder/zipfiles'\n",
    "if os.path.exists(zipfilefolder) is False:\n",
    "    os.makedirs(zipfilefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating new archive adam_data_folder/zipfiles/classification_2_squiggle.zip\n",
      "creating new archive adam_data_folder/zipfiles/classification_1_narrowband.zip\n",
      "creating new archive adam_data_folder/zipfiles/classification_2_narrowband.zip\n",
      "creating new archive adam_data_folder/zipfiles/classification_1_noise.zip\n",
      "creating new archive adam_data_folder/zipfiles/classification_2_noise.zip\n",
      "creating new archive adam_data_folder/zipfiles/classification_1_narrowbanddrd.zip\n",
      "creating new archive adam_data_folder/zipfiles/classification_2_narrowbanddrd.zip\n"
     ]
    }
   ],
   "source": [
    "#Figure out how many zip files we need to make\n",
    "\n",
    "for k, v, in training_set_group_by_class.iteritems():\n",
    "    \n",
    "    fnames = [outputpng_folder + '/' + vv['uuid'] + '.dat.png' for vv in v]  #yes, files are <uuid>.dat.png :/\n",
    "    \n",
    "    count = 1\n",
    "    for fn in fnames:\n",
    "        \n",
    "        archive_name = '{}/classification_{}_{}.zip'.format(zipfilefolder, count, k)\n",
    "        \n",
    "        if os.path.exists(archive_name):\n",
    "            zz = zipfile.ZipFile(archive_name, mode='a')\n",
    "        else:\n",
    "            print 'creating new archive', archive_name\n",
    "            zz = zipfile.ZipFile(archive_name, mode='w')\n",
    "           \n",
    "        zz.write(fn)\n",
    "        zz.close()\n",
    "        \n",
    "        #if archive_name folder exceeds 75 MB, increase count to create a new one\n",
    "        if os.path.getsize(archive_name) > 75.0*1024**2:\n",
    "            count += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating new archive adam_data_folder/zipfiles/testset_squiggle.zip\n",
      "creating new archive adam_data_folder/zipfiles/testset_narrowband.zip\n",
      "creating new archive adam_data_folder/zipfiles/testset_noise.zip\n",
      "creating new archive adam_data_folder/zipfiles/testset_narrowbanddrd.zip\n"
     ]
    }
   ],
   "source": [
    "for k, v, in test_set_group_by_class.iteritems():\n",
    "    \n",
    "    fnames = [outputpng_folder + '/' + vv['uuid'] + '.dat.png' for vv in v]  #yes, files are <uuid>.dat.png :/\n",
    "    \n",
    "    for fn in fnames:\n",
    "        \n",
    "        archive_name = '{}/testset_{}.zip'.format(zipfilefolder, k)\n",
    "        \n",
    "        if os.path.exists(archive_name):\n",
    "            zz = zipfile.ZipFile(archive_name, mode='a')\n",
    "        else:\n",
    "            print 'creating new archive', archive_name\n",
    "            zz = zipfile.ZipFile(archive_name, mode='w')\n",
    "           \n",
    "        zz.write(fn)\n",
    "        zz.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2.3G\r\n",
      "drwxr-x--- 5 sfa7-9e7464df3e1117-5edfd8a0d95d users 4.0K Jun  1 04:44 ..\r\n",
      "-rw-r----- 1 sfa7-9e7464df3e1117-5edfd8a0d95d users  58M Jun  1 04:49 classification_2_squiggle.zip\r\n",
      "-rw-r----- 1 sfa7-9e7464df3e1117-5edfd8a0d95d users  76M Jun  1 04:49 classification_1_narrowband.zip\r\n",
      "-rw-r----- 1 sfa7-9e7464df3e1117-5edfd8a0d95d users  58M Jun  1 04:49 classification_2_narrowband.zip\r\n",
      "-rw-r----- 1 sfa7-9e7464df3e1117-5edfd8a0d95d users  76M Jun  1 04:49 classification_1_noise.zip\r\n",
      "-rw-r----- 1 sfa7-9e7464df3e1117-5edfd8a0d95d users  60M Jun  1 04:49 classification_2_noise.zip\r\n",
      "-rw-r----- 1 sfa7-9e7464df3e1117-5edfd8a0d95d users  76M Jun  1 04:49 classification_1_narrowbanddrd.zip\r\n",
      "-rw-r----- 1 sfa7-9e7464df3e1117-5edfd8a0d95d users  57M Jun  1 04:49 classification_2_narrowbanddrd.zip\r\n",
      "-rw-r----- 1 sfa7-9e7464df3e1117-5edfd8a0d95d users  76M Jun  1 04:53 classification_1_squiggle.zip\r\n",
      "-rw-r----- 1 sfa7-9e7464df3e1117-5edfd8a0d95d users  57M Jun  1 04:53 testset_squiggle.zip\r\n",
      "-rw-r----- 1 sfa7-9e7464df3e1117-5edfd8a0d95d users  57M Jun  1 04:53 testset_narrowband.zip\r\n",
      "-rw-r----- 1 sfa7-9e7464df3e1117-5edfd8a0d95d users  58M Jun  1 04:53 testset_noise.zip\r\n",
      "drwxr-x--- 2 sfa7-9e7464df3e1117-5edfd8a0d95d users 4.0K Jun  1 04:53 .\r\n",
      "-rw-r----- 1 sfa7-9e7464df3e1117-5edfd8a0d95d users  57M Jun  1 04:53 testset_narrowbanddrd.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls -alrth my_team_name_data_folder/zipfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
