{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Judging Criteria\n",
    "\n",
    "This document shows where to get the test data set, and explains how the judging will be done for the \"Best Classification\" system. \n",
    "\n",
    "Read the [Step 1: Get Data tutorial](tutorials/Step_1_Get_Data.ipynb#Test-Data-Set) for information on where to get the training and test data sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Generate CSV File with Scores\n",
    "\n",
    "For each simulated file in the test data set, your job is to create a CSV file where each line contains the signal's UUID, followed by scores for each signal class. (The signal class with the highest score would be your model's class estimation. Typically these's scores are the probability estimates for each class.)\n",
    "\n",
    "Extract the contents of the file and use `ibmseti` python package to read each file, just like you would the training data. The UUID is for each file found in the header. See [Step_2_reading_SETI_code_challenge_data.ipynb](tutorials/Step_2_reading_SETI_code_challenge_data.ipynb) for examples of reading the data.  \n",
    "\n",
    "For each data file in the test set, generate the appropriate spectrogram and pass that to your signal classifier to calculate the scores for each class. Then write the results to an output csv files\n",
    "\n",
    "For example, each line in the CSV file should look like:\n",
    "\n",
    "  * `abdefg-adbc12-23234-123123-cvaf, 0.1, 0.023, 0.451, 0.232, 0.001, 0.07, 0.0083`\n",
    "\n",
    "**THE COLUMN ORDER OF THE NUMBERS IS CRITICAL! THEY MUST BE THE SCORE FOR EACH CLASS IN THIS ORDER:**\n",
    "\n",
    "  * `uuid, brightpixel, narrowband, narrowbanddrd, noise, squarepulsednarrowband, squiggle, squigglesquarepulsednarrowband`\n",
    "\n",
    "In the example above, the `abdefg-adbc12-23234-123123-cvaf` would be labeled as a `narrowbanddrd` because it has the highest score. \n",
    "\n",
    "#### Example PseudoCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ibmseti\n",
    "import csv\n",
    "import ALL LIBS FOR YOUR CLASSIFIER (tensorflow, Watson, etc)\n",
    "\n",
    "my_model #this is your trained signal classification model\n",
    "my_output_results = mydatafolder + '/signal_class_results.csv'\n",
    "zz = zipfile.ZipFile(mydatafolder + '/' + 'primary_testset.zip')\n",
    "\n",
    "for fn in zz.namelist():\n",
    "    data = zz.open(fn).read()\n",
    "    aca = ibmseti.compamp.SimCompamp(data)\n",
    "    uuid = aca.header()['uuid']\n",
    "    spectrogram = draw_spectrogram(aca) #whatever signal processing code you need would go in your `draw_spectrogram` code\n",
    "    \n",
    "    #cr = class results. In this example, it's a dictionary. But in your experience it could be something else\n",
    "    #       like a simple list.\n",
    "    cr = my_model.classify(spectrogram)\n",
    "    \n",
    "    with open(my_output_results, 'a') as csvfile:\n",
    "        fwriter = csv.writer(csvfile, delimiter=',')\n",
    "        fwrite.writerow([uuid, cr['brightpixel'], cr['narrowband'], cr['narrowbanddrd'],\n",
    "                         cr['noise'], cr['squarepulsednarrowband'], cr['squiggle'],\n",
    "                         cr['squigglesquarepulsednarrowband']\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measured by Logistical Loss\n",
    "\n",
    "In this contest, because we are using all the scores, we'll use the [LogLoss function](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html) as a measure of your model. These details will be found in an upcoming notebook. There will be a website that you use to submit your CSV file containing the scores for your team. This website will also contain a scoreboard. This will be implemented **after** the hackathon on June 11th -- more details to come. \n",
    "\n",
    "## Submit Your Results\n",
    "\n",
    "### Get your CSV File\n",
    "\n",
    "If you are running this on IBM DSX (IBM Apache Spark), you'll need to get your `.csv` file to your local working directory in order to submit your results to the Scoreboard website.\n",
    "\n",
    "The best way to get your data is to move your `.csv` file to your Object Storage account that is provided in DSX. Then, move the `.csv` file from your Object Storage to your local directory.\n",
    "[This tutorial shows you the basic steps to move data to and from your Object Storage instance.](tutorials/General_move_data_to_from_Object_Storage.ipynb)  \n",
    "\n",
    "### Submit your CSV File\n",
    "\n",
    "We are currently constructing a Team Scoreboard for participants. This will be used first at the hackathon. After the hackathon, we will make scoreboard available for the code challenge particitipants.   We will send you notification when the Scoreboard is ready!  We expect the Scoreboard to go live on June 15th!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
